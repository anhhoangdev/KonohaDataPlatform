apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: kyuubi-dbt
  namespace: kyuubi
spec:
  interval: 1h
  chart:
    spec:
      chart: kyuubi
      version: "0.1.0"
      sourceRef:
        kind: HelmRepository
        name: internal-charts
        namespace: flux-system
      interval: 5m
  values:
    replicaCount: 1

    # Kyuubi server image (custom built)
    image:
      repository: kyuubi-server
      pullPolicy: Never
      tag: "1.10.0"

    podAnnotations:
      karpenter.sh/do-not-disrupt: "true"

    server:
      thriftBinary:
        enabled: true
      rest:
        enabled: true
      thriftHttp:
        enabled: true
      mysql:
        enabled: false

    kyuubiConfDir: /opt/kyuubi/conf

    kyuubiConf:
      kyuubiEnv: |
        export KYUUBI_HOME="/opt/kyuubi"

      # Kyuubi configuration with Iceberg support
      kyuubiDefaults: |
        # Kubernetes and Spark basic configuration
        spark.master k8s://https://kubernetes.default:443
        spark.submit.deployMode cluster

        # Kyuubi HA and session management
        kyuubi.ha.enabled=true
        kyuubi.ha.addresses=kyuubi-zk-zookeeper:2181
        kyuubi.ha.namespace=kyuubi-dbt
        kyuubi.ha.zookeeper.client.port=2181

        kyuubi.operation.result.format=arrow
        kyuubi.engine.share.level=USER
        kyuubi.engine.initialize.sql=SELECT 1
        kyuubi.session.engine.check.interval=PT5S
        kyuubi.session.engine.idle.timeout=PT30S
        kyuubi.session.engine.initialize.timeout=PT8M
        kyuubi.session.engine.spark.main.resource=local:///opt/kyuubi/externals/engines/spark/kyuubi-spark-sql-engine.jar
        kyuubi.operation.result.max.rows=100000
        kyuubi.metadata.store.jdbc.database.type=SQLITE

        # Kubernetes cleanup
        kyuubi.kubernetes.spark.cleanupTerminatedDriverPod.kind=ALL
        kyuubi.kubernetes.spark.cleanupTerminatedDriverPod.checkInterval=PT5M
        kyuubi.kubernetes.spark.forciblyRewriteDriverPodName.enabled=false
        kyuubi.kubernetes.spark.forciblyRewriteExecutorPodNamePrefix.enabled=false

        kyuubi.frontend.bind.host=0.0.0.0
        kyuubi.session.conf.ignore.list=spark.driver.memory,spark.driver.cores,spark.executor.memory,spark.executor.cores,spark.executor.instances,spark.executor.memoryOverhead,spark.kubernetes.driver.request.cores,spark.kubernetes.executor.request.cores,spark.kubernetes.executor.limit.cores,spark.kubernetes.executor.podTemplateFile,spark.app.name,spark.kubernetes.container.image,spark.sql.autoBroadcastJoinThreshold,spark.dynamicAllocation.minExecutors,spark.dynamicAllocation.maxExecutors,spark.dynamicAllocation.initialExecutors,spark.shuffle.service.enabled,spark.dynamicAllocation.shuffleTracking.enabled,spark.dynamicAllocation.executorAllocationRatio

      log4j2: |
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration status="INFO">
            <Appenders>
                <Console name="stdout" target="SYSTEM_OUT">
                    <PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss.SSS} %p %c: %m%n"/>
                    <Filters>
                        <RegexFilter regex=".*Thrift error occurred during processing of message.*" onMatch="DENY" onMismatch="NEUTRAL"/>
                        <RegexFilter regex=".*No data or no sasl data in the stream.*" onMatch="DENY" onMismatch="ACCEPT" />
                    </Filters>
                </Console>
            </Appenders>
            <Loggers>
                <Root level="INFO">
                    <AppenderRef ref="stdout"/>
                </Root>
                <Logger name="org.apache.kyuubi.ctl.ServiceControlCli" level="error" additivity="false">
                    <AppenderRef ref="stdout"/>
                </Logger>
                <Logger name="org.apache.hive.beeline.KyuubiBeeLine" level="error" additivity="false">
                    <AppenderRef ref="stdout"/>
                </Logger>
                <Logger level="off" name="org.apache.thrift.server.TThreadPoolServer"></Logger>
            </Loggers>
        </Configuration>

    sparkConfDir: /opt/spark/conf
    sparkConf:
      sparkDefaults: |
        # Kubernetes and basic Spark configuration
        spark.master k8s://https://kubernetes.default:443
        spark.submit.deployMode cluster

        # Kubernetes authentication
        spark.kubernetes.authenticate.submission.caCertFile /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        spark.kubernetes.authenticate.submission.oauthTokenFile /var/run/secrets/kubernetes.io/serviceaccount/token
        spark.kubernetes.authenticate.driver.serviceAccountName kyuubi-rw

        # ICEBERG CONFIGURATION - Simplified setup
        spark.sql.extensions org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
        
        # Default catalog configured for Iceberg
        spark.sql.catalog.spark_catalog org.apache.iceberg.spark.SparkCatalog
        spark.sql.catalog.spark_catalog.type hive
        spark.sql.catalog.spark_catalog.uri thrift://hive-metastore:9083
        spark.sql.catalog.spark_catalog.warehouse s3a://warehouse/
        
        # Dedicated Iceberg catalog (optional - for explicit Iceberg usage)
        spark.sql.catalog.iceberg org.apache.iceberg.spark.SparkCatalog
        spark.sql.catalog.iceberg.type hive
        spark.sql.catalog.iceberg.uri thrift://hive-metastore:9083
        spark.sql.catalog.iceberg.warehouse s3a://warehouse/

        # Enable Iceberg support in Hive Metastore
        spark.hive.metastore.uris thrift://hive-metastore:9083
        spark.sql.catalogImplementation hive
        
        # Iceberg optimizations
        spark.sql.adaptive.enabled true
        spark.sql.adaptive.coalescePartitions.enabled true
        spark.sql.adaptive.skewJoin.enabled true

        # Spark serialization and SQL
        spark.serializer org.apache.spark.serializer.KryoSerializer
        spark.sql.parquet.filterPushdown true
        spark.sql.parquet.mergeSchema false
        spark.sql.legacy.parquet.nanosAsLong false
        spark.sql.legacy.setCommandRejectsSparkCoreConfs false
        spark.sql.legacy.allowNonEmptyLocationInCTAS true
        spark.speculation false

        # Spark on Kubernetes settings - CRITICAL: Use our custom Iceberg-enabled image
        spark.kubernetes.namespace kyuubi
        spark.kubernetes.container.image spark-engine-iceberg:3.5.0-1.4.2
        spark.kubernetes.driver.podTemplateContainerName spark-kubernetes-driver
        spark.kubernetes.executor.podTemplateContainerName spark-kubernetes-executor
        spark.kubernetes.submission.connectionTimeout 120000
        spark.kubernetes.submission.requestTimeout 120000
        spark.kubernetes.driver.connectionTimeout 120000
        spark.kubernetes.driver.requestTimeout 120000
        spark.kubernetes.pyspark.pythonVersion 3

        # Datetime and int96 corrections
        spark.sql.avro.datetimeRebaseModeInWrite CORRECTED
        spark.sql.avro.datetimeRebaseModeInRead CORRECTED
        spark.sql.parquet.datetimeRebaseModeInRead CORRECTED
        spark.sql.parquet.datetimeRebaseModeInWrite CORRECTED
        spark.sql.parquet.int96RebaseModeInRead CORRECTED
        spark.sql.parquet.int96RebaseModeInWrite CORRECTED

        # Spark metrics and event logging
        spark.eventLog.enabled true
        spark.metrics.namespace ${spark.app.name}
        spark.eventLog.dir s3a://logs/kyuubi-internal
        spark.eventLog.rolling.enabled false
        spark.eventLog.rolling.maxFileSize 128m

        # Prometheus metrics
        spark.ui.prometheus.enabled true
        spark.kubernetes.driver.annotation.prometheus.io/scrape true
        spark.kubernetes.driver.annotation.prometheus.io/path /metrics/executors/prometheus/
        spark.kubernetes.driver.annotation.prometheus.io/port 4040

        # Hadoop and S3 configuration
        spark.hadoop.fs.s3a.impl org.apache.hadoop.fs.s3a.S3AFileSystem
        spark.hadoop.fs.s3.impl org.apache.hadoop.fs.s3a.S3AFileSystem
        spark.hadoop.fs.s3a.aws.credentials.provider com.amazonaws.auth.WebIdentityTokenCredentialsProvider
        spark.hadoop.fs.s3a.fast.upload true
        spark.hadoop.fs.s3a.multiobjectdelete.enable true
        spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version 2
        spark.hive.input.format org.apache.hadoop.hive.ql.io.HiveInputFormat

        # Default resource settings
        spark.app.name dbt
        spark.executor.instances 1
        spark.executor.memory 2g
        spark.executor.cores 2
        spark.driver.memory 5g
        spark.driver.memoryOverhead 1g
        spark.sql.autoBroadcastJoinThreshold 52428800
        spark.kubernetes.executor.request.cores 1800m
        spark.kubernetes.executor.limit.cores 2
        spark.kubernetes.driver.request.cores 900m
        spark.kubernetes.driver.limit.cores 1
        spark.kubernetes.driver.podTemplateFile /opt/kyuubi/templates/driver-pod-template.yaml
        spark.kubernetes.executor.podTemplateFile /opt/kyuubi/templates/executor-pod-template.yaml
        spark.kubernetes.executor.node.selector.karpenter.k8s.aws/instance-category r

        # Dynamic allocation
        spark.dynamicAllocation.enabled true
        spark.shuffle.service.enabled false
        spark.dynamicAllocation.minExecutors 0
        spark.dynamicAllocation.maxExecutors 9
        spark.dynamicAllocation.initialExecutors 1
        spark.dynamicAllocation.executorIdleTimeout 60s
        spark.dynamicAllocation.cachedExecutorIdleTimeout 30min
        spark.dynamicAllocation.executorAllocationRatio 0.2
        spark.dynamicAllocation.shuffleTracking.enabled true
        spark.dynamicAllocation.shuffleTracking.timeout 30min
        spark.dynamicAllocation.schedulerBacklogTimeout 1s
        spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 1s
        spark.cleaner.periodicGC.interval 5min

        # Yunikorn scheduler
        spark.kubernetes.scheduler.name yunikorn
        spark.kubernetes.driver.label.queue root.dbt.internal
        spark.kubernetes.executor.label.queue root.dbt.internal

        # Pod labels
        spark.kubernetes.driver.label.owner data-engineer
        spark.kubernetes.executor.label.owner data-engineer
        spark.kubernetes.driver.label.model dbt
        spark.kubernetes.executor.label.model dbt
        spark.kubernetes.driver.label.dag_id dbt
        spark.kubernetes.executor.label.dag_id dbt
        spark.kubernetes.driver.label.task_id dbt
        spark.kubernetes.executor.label.task_id dbt

      log4j2: |
        rootLogger.level = info
        rootLogger.appenderRef.stdout.ref = console

        appender.console.type = Console
        appender.console.name = console
        appender.console.target = SYSTEM_ERR
        appender.console.layout.type = PatternLayout
        appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n%ex

        logger.repl.name = org.apache.spark.repl.Main
        logger.repl.level = warn

        logger.thriftserver.name = org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver
        logger.thriftserver.level = warn

        # Quiet third party logs
        logger.jetty1.name = org.sparkproject.jetty
        logger.jetty1.level = warn
        logger.jetty2.name = org.sparkproject.jetty.util.component.AbstractLifeCycle
        logger.jetty2.level = error
        logger.parquet1.name = org.apache.parquet
        logger.parquet1.level = error
        logger.parquet2.name = parquet
        logger.parquet2.level = error

        logger.RetryingHMSHandler.name = org.apache.hadoop.hive.metastore.RetryingHMSHandler
        logger.RetryingHMSHandler.level = fatal
        logger.FunctionRegistry.name = org.apache.hadoop.hive.ql.exec.FunctionRegistry
        logger.FunctionRegistry.level = error

        # Suppress Thrift warnings
        appender.console.filter.1.type = RegexFilter
        appender.console.filter.1.regex = .*Thrift error occurred during processing of message.*
        appender.console.filter.1.onMatch = deny
        appender.console.filter.1.onMismatch = neutral

    volumes:
    - name: spark-pod-templates
      configMap:
        name: spark-pod-templates-configmap

    volumeMounts:
    - name: spark-pod-templates
      mountPath: /opt/kyuubi/templates

    monitoring:
      prometheus:
        enabled: true

    metricsReporters: PROMETHEUS

    rbac:
      create: true
      rules:
      - apiGroups: [""]
        resources:
          - pods
          - configmaps
          - services
          - persistentvolumeclaims
        verbs:
          - create
          - delete
          - deletecollection
          - get
          - list
          - patch
          - update
          - watch

    serviceAccount:
      create: false
      name: kyuubi-rw

    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 200m
        memory: 500Mi

    podMonitor:
      enabled: false

    serviceMonitor:
      enabled: true
      labels:
        release: kube-prometheus-stack
      endpoints:
        - port: prometheus
          path: /metrics
          interval: 15s

    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: service
                operator: In
                values: ["general-long-live"]
              - key: karpenter.sh/capacity-type
                operator: In
                values: ["on-demand"]
              - key: kubernetes.io/arch
                operator: In
                values: ["arm64"]
      podAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/instance
              operator: In
              values:
              - kyuubi-dbt
          topologyKey: topology.kubernetes.io/zone
          namespaces:
            - kyuubi

    tolerations:
      - effect: NoSchedule
        key: kubernetes.io/arch
        operator: Equal
        value: arm64 